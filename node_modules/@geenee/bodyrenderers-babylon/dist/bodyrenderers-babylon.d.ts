import { SceneRenderer, CanvasMode, ScenePlugin, Size, Renderer, ShaderPlugin, ImageTexture } from '@geenee/armature';
import { PoseResult, FaceResult, PosePoints } from '@geenee/bodyprocessors';
import * as babylon from '@babylonjs/core';
import { SkeletonMap, PoseTuneParams, SpineCurve, OutfitParams, DilationShader } from '@geenee/bodyrenderers-common';

/**
 * Generic babylon.js renderer
 *
 * Extends {@link @geenee/armature!SceneRenderer} for the babylon.js
 * rendering engine. BabylonRenderer does basic initialization of
 * engine, scene, and camera. It's a generic class that should be
 * parameterized by type of processing results to build an app using
 * particular implementation of {@link @geenee/armature!Processor}.
 *
 * @typeParam ResultT - Type of processing results
 */
declare class BabylonRenderer<ResultT extends {} = {}> extends SceneRenderer<ResultT, babylon.Scene> {
    /** Rendering engine */
    protected renderer: babylon.Engine;
    /** Camera instance */
    protected camera: babylon.UniversalCamera;
    /** Camera's vertical angle of view */
    protected cameraAngle: number;
    /**
     * Constructor
     *
     * @param container - Container of {@link @geenee/armature!ResponsiveCanvas}
     * @param mode - Fitting mode
     * @param mirror - Mirror the output
     */
    constructor(container: HTMLElement, mode?: CanvasMode, mirror?: boolean);
    /**
     * Update and render the scene
     *
     * Virtual method updating and rendering 3D scene.
     * For babylon.js engine calls `this.scene.render()`.
     *
     * @override
     */
    protected updateScene(): void;
    /**
     * Dispose renderer object
     *
     * Extended to dispose scene and engine.
     *
     * @override
     */
    dispose(): void;
    /**
     * Set camera parameters
     *
     * Setups {@link BabylonRenderer#camera} instance according to
     * parameters provided by {@link @geenee/armature!Processor}.
     *
     * @param size - Resolution of input video
     * @param ratio - Aspect ration of input video
     * @override
     */
    setupCamera(ratio: number, angle: number): void;
}
/**
 * Generic plugin for {@link BabylonRenderer}
 *
 * Extends {@link @geenee/armature!ScenePlugin} for babylon.js
 * rendering engine. BabylonPlugin is an abstract generic class
 * simplifying library's API, it doesn't implement any logic and
 * can be used as basis for actual render plugins. It should be
 * parameterized by type of processing results to build a plugin
 * for the implementation of {@link @geenee/armature!Processor}.
 *
 * @typeParam ResultT - Type of processing results
 */
declare class BabylonPlugin<ResultT extends {} = {}> extends ScenePlugin<ResultT, babylon.Scene> {
}
/**
 * Abstract plugin for {@link PoseRenderer}
 *
 * Specializes the {@link BabylonPlugin} generic for
 * {@link @geenee/bodyprocessors!PoseResult}. This's
 * abstract plugin that doesn't implement any logic.
 */
declare class PosePlugin extends BabylonPlugin<PoseResult> {
}
/**
 * Abstract plugin for {@link FaceRenderer}
 *
 * Specializes the {@link BabylonPlugin} generic for
 * {@link @geenee/bodyprocessors!FaceResult}. This's
 * abstract plugin that doesn't implement any logic.
 */
declare class FacePlugin extends BabylonPlugin<FaceResult> {
}

/**
 * Generic babylon.js renderer
 *
 * Extends {@link @geenee/armature!SceneRenderer} for the babylon.js
 * rendering engine. BabylonUniRenderer requires only one layer of
 * {@link @geenee/armature!ResponsiveCanvas} and renders processed
 * video stream as scene's background. Thus WebGL context is shared
 * between Babylon engine and {@link @geenee/armature!ShaderRenderer}.
 * This provides perfect synchronization between video and 3D content.
 * BabylonUniRenderer does basic initialization of engine, scene, and
 * camera instances. It is a generic class that should be further
 * parameterized by type of processing results to build an app using
 * particular implementation of {@link @geenee/armature!Processor}.
 *
 * @typeParam ResultT - Type of processing results
 */
declare class BabylonUniRenderer<ResultT extends {} = {}> extends SceneRenderer<ResultT, babylon.Scene> {
    /** Rendering engine */
    protected renderer: babylon.Engine;
    /** Video layer */
    protected layer: babylon.Layer;
    /** Camera instance */
    protected camera: babylon.UniversalCamera;
    /** Camera's vertical angle of view */
    protected cameraAngle: number;
    /**
     * Constructor
     *
     * @param container - Container of {@link @geenee/armature!ResponsiveCanvas}
     * @param mode - Fitting mode
     * @param mirror - Mirror the output
     */
    constructor(container: HTMLElement, mode?: CanvasMode, mirror?: boolean);
    /**
     * Update the video layer
     *
     * Renders processed frame to texture of video layer.
     *
     * @param stream - Captured video frame
     * @override
     */
    protected updateVideo(stream: HTMLCanvasElement): void;
    /**
     * Update and render the scene
     *
     * Virtual method updating and rendering 3D scene.
     * For babylon.js engine calls `this.scene.render()`.
     *
     * @override
     */
    protected updateScene(): void;
    /**
     * Dispose renderer object
     *
     * Extended to dispose scene and engine.
     *
     * @override
     */
    dispose(): void;
    /**
     * Set video parameters
     *
     * Resizes video texture and rendering shader.
     *
     * @param size - Resolution of input video
     * @param ratio - Aspect ration of input video
     * @override
     */
    setupVideo(size: Size, ratio?: number): void;
    /**
     * Set camera parameters
     *
     * Setups {@link BabylonRenderer#camera} instance according to
     * parameters provided by {@link @geenee/armature!Processor}.
     *
     * @param size - Resolution of input video
     * @param ratio - Aspect ration of input video
     * @override
     */
    setupCamera(ratio: number, angle: number): void;
}
/**
 * Abstract renderer for {@link @geenee/bodyprocessors!PoseProcessor}
 *
 * Specializes {@link BabylonUniRenderer} generic for
 * {@link @geenee/bodyprocessors!PoseResult}.This is
 * abstract renderer that doesn't implement any logic.
 */
declare class PoseRenderer extends BabylonUniRenderer<PoseResult> {
}
/**
 * Abstract renderer for {@link @geenee/bodyprocessors!FaceProcessor}
 *
 * Specializes {@link BabylonUniRenderer} generic for
 * {@link @geenee/bodyprocessors!FaceResult}.This is
 * abstract renderer that doesn't implement any logic.
 */
declare class FaceRenderer extends BabylonUniRenderer<FaceResult> {
}

/**
 * Plugin assigning head pose to a scene node
 *
 * Plugin attaches provided scene node to the head.
 * Pose of the node (translation + rotation + scale)
 * continuously updates according to pose estimation
 * by {@link @geenee/bodyprocessors!FaceProcessor}.
 * Children nodes inherently include this transform.
 * The node can be seen as a virtual placeholder for
 * real object. It's recommended to attach top-level
 * nodes that don't include transforms relative to
 * parent, otherwise head transform that is a pose
 * in the world frame will be applied on top of them
 * (will be treated as relative instead of absolute).
 * Optionally anisotropic fine-tuning of the scale can
 * be applied. In this case model will additionally
 * adapt to shape of the face. If face isn't detected
 * by FaceProcessor plugin recursively hides the node.
 * One of approaches to accurately align meshes with
 * a face/head when modeling a scene is to make them
 * children of one node at the origin and set their
 * relative transforms using face/head base mesh as
 * the reference, then instantiate HeadTrackPlugin
 * for this scene node. You can also apply relative
 * transforms of children of the head-attached parent
 * node programmatically. It's useful to add occluder
 * model (base mesh of a head) as a child of the node.
 * Another possible but less scalable approach is to
 * have all meshes be built relative to the origin and
 * aligned with the base mesh of face/head, in this
 * case you can create HeadTrackPlugin for each mesh.
 * This can be handy when parts are stored separately.
 */
declare class HeadTrackPlugin extends BabylonPlugin<FaceResult> {
    protected node: babylon.TransformNode;
    protected shapeScale: boolean;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param shapeScale - Tune scale according to shape of the face
     */
    constructor(node: babylon.TransformNode, shapeScale?: boolean);
    /**
     * Update pose of the node
     *
     * Updates node's transform (translation+rotation+scale) according to
     * the pose estimated by {@link @geenee/bodyprocessors!FaceProcessor}.
     * If face isn't detected plugin recursively hides the attached node.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: FaceResult, stream: HTMLCanvasElement): Promise<void>;
}

/**
 * Plugin assigning face point pose to a scene node
 *
 * Plugin attaches provided node to the face point.
 * Pose of the node (translation + rotation + scale)
 * continuously updates according to pose estimation
 * by {@link @geenee/bodyprocessors!FaceProcessor}.
 * Children nodes inherently include this transform.
 * The node can be seen as a virtual placeholder for
 * real object. It's recommended to attach top-level
 * nodes that don't include transforms relative to
 * parent, otherwise head transform that is a pose
 * in the world frame will be applied on top of them
 * (will be treated as relative instead of absolute).
 * Optionally anisotropic fine-tuning of the scale can
 * be applied. In this case model will additionally
 * adapt to shape of the face. If face isn't detected
 * by FaceProcessor plugin recursively hides the node.
 * One of approaches to accurately align meshes with
 * a face point when modeling a scene is to make them
 * children of a node which origin coincide with the
 * corresponding vertex of the reference face mesh,
 * set their relative transforms using base mesh as
 * the reference, then instantiate FaceTrackPlugin
 * for this scene node. You can also apply relative
 * transforms of children of the face-attached parent
 * node programmatically. It's useful to add occluder
 * model (base mesh of a head) as a child of the node.
 * This can be handy when parts are stored separately.
 */
declare class FaceTrackPlugin extends BabylonPlugin<FaceResult> {
    protected node: babylon.TransformNode;
    protected facePoint: number;
    protected shapeScale: boolean;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param facePoint - Index of the face vertex
     * @param shapeScale - Tune scale according to shape of the face
     */
    constructor(node: babylon.TransformNode, facePoint?: number, shapeScale?: boolean);
    /**
     * Update pose of the model
     *
     * Updates node's pose (translation + rotation + scale) according to
     * to the estimation from {@link @geenee/bodyprocessors!FaceProcessor}.
     * If face isn't detected plugin recursively hides the attached node.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: FaceResult, stream: HTMLCanvasElement): Promise<void>;
}

/**
 * Plugin assigning face mesh to geometry to a scene node
 *
 * Plugin controls geometry of a scene node. Vertices are
 * continuously updated using face mesh points estimated
 * by {@link @geenee/bodyprocessors!FaceProcessor}. Node's
 * mesh must have geometry compatible with detected face
 * mesh, preferably created from the reference face model.
 * The main requirement is that uv map must be compatible.
 * The node can be seen as a virtual placeholder for real
 * object. It's recommended to attach top-level nodes that
 * don't have transforms relative to the root, otherwise
 * this transforms will be applied to absolute positions
 * of 3d points of the face (points will act as relative).
 * One of approaches to create node for accurate face mask
 * when modeling a scene is to import reference face model
 * as top-level scene node and add one or more materials
 * which textures are compatible with reference's uv map.
 * And then instantiate FaceMaskPlugin for this scene node.
 * In {@link FaceMaskPlugin#load | load()} plugin replaces
 * geometry of attached node's mesh with one provided by
 * FaceProcessor, defined indices, uv mapping and normals.
 * As soon as uv maps of the scene mesh and the reference
 * model are compatible all materials will be applied the
 * same way as in the modeled scene. Vertices positions
 * are updated in {@link FaceMaskPlugin#update | update()}
 * method according to current face tracking estimations.
 */
declare class FaceMaskPlugin extends BabylonPlugin<FaceResult> {
    protected mesh?: babylon.Mesh | undefined;
    /** Number of points in detected mesh */
    readonly pointCont: number;
    /**
     * Constructor
     *
     * @param mesh - Scene mesh to attach
     */
    constructor(mesh?: babylon.Mesh | undefined);
    /**
     * Initialize plugin
     *
     * FaceMaskPlugin replaces geometry of attached mesh
     * by compatible with face estimated by FaceProcessor.
     * As soon as uv maps of the node and the reference
     * face model are compatible, materials/textures will
     * be applied the same way as in the modeled 3d scene.
     * Defines indices, uvs, normals, while positions are
     * updated in {@link FaceMaskPlugin#update | update()}.
     *
     * @param renderer - Renderer this plugin is attached to
     * @returns Promise resolving when initialization is finished
     * @override
     */
    load(renderer: Renderer<FaceResult>): Promise<void>;
    /**
     * Update geometry of the mesh
     *
     * Updates vertex positions according to points of the face
     * estimated by {@link @geenee/bodyprocessors!FaceProcessor}.
     * If face is not detected, plugin hides the attached mesh.
     *
     * @param result - Results of video processing
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: FaceResult, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Set/attach a scene mesh
     *
     * Rebuilds geometry of the mesh node to be compatible
     * with face mesh points estimated by FaceProcessor.
     * As soon as uv maps of the node and the reference
     * face model are compatible, materials/textures will
     * be applied the same way as in the modeled 3d scene.
     *
     * @param mesh - Scene mesh node to attach
     * @returns Promise resolving when initialization is finished
     * @virtual
     */
    setMesh(mesh?: babylon.Mesh): Promise<void>;
}

/** Bone transformation */
interface BoneTransform {
    /** Head position */
    position: babylon.Vector3;
    /** Bone orientation */
    rotation: babylon.Quaternion;
}
/** Skeleton transformations */
declare type SkeletonTransforms = SkeletonMap<BoneTransform>;
/** Skeleton - bones of the rig */
declare type SkeletonNodes = SkeletonMap<babylon.TransformNode>;
/**
 * Pose plugin aligning node's rig with keypoints
 *
 * Universal plugin aligning node's rig and pose estimated by
 * {@link @geenee/bodyprocessors!PoseProcessor}. It's a base of
 * try-on, twin, and other plugins. You can use this class as a
 * starting point and customize alignment method or add features.
 * Basically, PoseAlignPlugin evaluates positions and rotations
 * of armature bones based on 3D pose keypoints, then applies
 * these transforms to bones following the armature hierarchy.
 * Plugin supports rigs compatible with Mixamo, for example any
 * Ready Player Me avatar. This is the most common standard of
 * rigs for human-like models supported by many game engines.
 * Provided node must contain an armature among its children.
 * Armature bones must follow Mixamo / RPM naming convention.
 * Models rigged and skinned manually or using Mixamo tool can
 * variate depending on anthropomorphous topology of the model.
 * PoseAlignPlugin can apply number of fine-tuning adjustments
 * to basic alignment improving model fitting or making it look
 * more natural. {@link PoseTuneParams} explains tuning options.
 * By default the plugin is fine-tuned for RPM avatars so you
 * can simply replace person with the avatar model in the scene.
 */
declare class PoseAlignPlugin extends PosePlugin {
    protected node?: babylon.TransformNode | undefined;
    protected tune: PoseTuneParams;
    /** Reference to model's skeleton */
    protected skeleton?: babylon.Skeleton;
    /** Bones of the model's rig */
    protected skeletonNodes?: SkeletonNodes;
    /** Shape of spine */
    protected spineCurve?: SpineCurve;
    /** Reference length of the model */
    protected avatarLength: number;
    /** Pose score threshold */
    readonly alignScore = 0.9;
    /** Keypoint visibility threshold */
    readonly alignVisibility = 0.9;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param tune - Fine-tuning parameters
     */
    constructor(node?: babylon.TransformNode | undefined, tune?: PoseTuneParams);
    /**
     * Initialize plugin
     *
     * Parses and caches the rig/armature of the attached
     * scene node (one provided to plugin's constructor).
     * Precalculates geometrical parameters of skeleton.
     *
     * @param renderer - Renderer this plugin is attached to
     * @returns Promise resolving when initialization is finished
     * @override
     */
    load(renderer: Renderer<PoseResult>): Promise<void>;
    /**
     * Reset plugin
     *
     * Removes the attached node.
     *
     * @override
     */
    unload(): void;
    /**
     * Set/attach a scene node
     *
     * Parses and caches the rig/armature of the node.
     * Precalculates geometrical parameters of skeleton.
     *
     * @param node - Scene node to attach
     * @returns Promise resolving when initialization is finished
     * @virtual
     */
    setNode(node?: babylon.TransformNode): void;
    /**
     * Update skeleton of the scene node
     *
     * Evaluates positions, rotations and scales of node bones
     * based on estimation of 3D keypoints, then applies these
     * transformations to bones following hierarchy of armature.
     * Optionally {@link PoseTuneParams | fine-tunes} the basic
     * alignment to improve model fitting or make it more natural.
     * You can override this method to further tune model's rig
     * using provided estimations of bones as starting point.
     * Simply call `await super.update(result, stream);` and use
     * {@link PoseAlignPlugin#skeletonNodes} member storing refs
     * to all bones of the skeleton to access transformations.
     *
     * @param result - Pose estimation results
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: PoseResult, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Update spine skeleton
     *
     * @param anchors - Positions and axes of bones
     */
    protected updateSpine(anchors: SkeletonTransforms): void;
    /**
     * Update left hand skeleton
     *
     * @param anchors - Positions and axes of bones
     * @param points - Pose keypoints
     */
    protected updateHandL(anchors: SkeletonTransforms, points: PosePoints): void;
    /**
     * Update right hand skeleton
     *
     * @param anchors - Positions and axes of bones
     * @param points - Pose keypoints
     */
    protected updateHandR(anchors: SkeletonTransforms, points: PosePoints): void;
    /**
     * Update left leg skeleton
     *
     * @param anchors - Positions and axes of bones
     * @param points - Pose keypoints
     */
    protected updateLegL(anchors: SkeletonTransforms, points: PosePoints): void;
    /**
     * Update right leg skeleton
     *
     * @param anchors - Positions and axes of bones
     * @param points - Pose keypoints
     */
    protected updateLegR(anchors: SkeletonTransforms, points: PosePoints): void;
    /**
     * Estimate bone positions and axes
     *
     * Based on detected keypoints estimates bone transformations.
     * Position of bone if defined by 3D point itself, bone length
     * is the distance between keypoints connected by bone. Bone's
     * rotation is defined by its axes that are evaluated from
     * relative positions of adjacent keypoints. Method returns
     * only bone position and orientation axis, final transformation
     * of any bone can be found using the next bone in hierarchy.
     *
     * @param points - Pose keypoints
     * @param spineCurve - Shape of spine
     * @returns Bone transformations
     */
    protected estimateBones(points: PosePoints, spineCurve: SpineCurve): SkeletonTransforms;
    /**
     * Estimate bone position and orientation
     *
     * Position/translation of bone is defined by its head.
     * Rotation is defined by bone's basis axes, vector from
     * head to tail gives Y axis, X axis is provided, Z axis
     * is evaluated to form right-handed orthonormal basis.
     *
     * @param head - Bone's head (position)
     * @param tail - Bone's tail (end)
     * @param axisX - Direction of X axis
     * @returns Bone transformation
     */
    private estimateBone;
    /**
     * Set bone transformation
     *
     * Transformation is in the world coordinate frame. If bone
     * has parent we find relative transformation to follow the
     * skeleton hierarchy. Optionally scale of parent bone can
     * be adjusted to align head and reference (rest) position
     * of parent's tail (they have to be the same 3D point).
     *
     * @param transform - Global bone position and rotation
     * @param bone - Reference to bone instance
     * @param scale - Whether to scale parent bone
     * @virtual
     */
    protected alignBone(transform: BoneTransform, bone: babylon.TransformNode, scale?: boolean): void;
}

/**
 * Plugin implementing virtual try-on of avatar's outfit
 *
 * PoseOutfitPlugin is extension of {@link PoseAlignPlugin}
 * that allows to specify body meshes of the avatar's node
 * as occluders and optionally hide some child meshes (parts).
 * It's a good starting point for virtual try-on applications.
 * {@link OutfitParams} defines available options of outfit.
 * You can download any Ready Player Me avatar which outfit
 * similar to final result, edit its outfit, re-skin model if
 * necessary. Then simply use this plugin to build try-on app.
 * Armature bones must follow Mixamo / RPM naming convention.
 */
declare class PoseOutfitPlugin extends PoseAlignPlugin {
    protected outfit?: OutfitParams | undefined;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param outfit - Occluder and hidden parts
     * @param tune - Fine-tuning parameters
     */
    constructor(node?: babylon.TransformNode, outfit?: OutfitParams | undefined, tune?: PoseTuneParams);
    /**
     * Set/attach a scene node
     *
     * Method setNode() is extended to make occluders from specified
     * body meshes and optionally hide some child meshes according to
     * {@link OutfitParams | parameters}. Occluders are made the same
     * way {@link OccluderPlugin} does via overriding mesh materials.
     *
     * @param mesh - Scene node to attach
     * @returns Promise resolving when initialization is finished
     * @override
     */
    setNode(mesh?: babylon.TransformNode): void;
    /**
     * Set outfit parameters
     *
     * @param node - Scene node to attach
     * @param outfit - Occluder and hidden parts
     * @returns Promise resolving when initialization is finished
     */
    setOutfit(node?: babylon.TransformNode, outfit?: OutfitParams): void;
}

/**
 * Plugin rendering a digital twin
 *
 * {@link PoseAlignPlugin} extension for digital twins mirroring
 * the pose and residing beside a user. When rendering a twin we
 * do not translate bones to align with keypoint coordinates and
 * only preserve relative rotations. After projecting the detected
 * pose onto a twin, twin's scene node can be further transformed
 * relative to the initial position - centers of hips are the same.
 */
declare class PoseTwinPlugin extends PoseAlignPlugin {
    protected translation?: babylon.Vector3 | undefined;
    protected rotation?: babylon.Quaternion | undefined;
    protected scale?: number | undefined;
    /**
     * Constructor
     *
     * @param node - Scene node to attach
     * @param translation - Relative translation of the twin
     * @param rotation - Relative rotation of the twin
     * @param scale - Scale of the twin
     * @param tune - Fine-tuning parameters
     */
    constructor(node?: babylon.TransformNode, translation?: babylon.Vector3 | undefined, rotation?: babylon.Quaternion | undefined, scale?: number | undefined, tune?: PoseTuneParams);
    /**
     * Update skeleton of the scene node
     *
     * Method is extended to set twin's translation,
     * rotation, and scale relative to estimated pose.
     *
     * @param result - Pose estimation results
     * @param stream - Captured video frame
     * @returns Promise resolving when update is finished
     * @override
     */
    update(result: PoseResult, stream: HTMLCanvasElement): Promise<void>;
    /**
     * Update spine skeleton
     *
     * Overridden to ignore relative scaling.
     *
     * @param anchors - Positions and axes of bones
     * @override
     */
    protected updateSpine(anchors: SkeletonTransforms): void;
    /**
     * Set bone aligning transformation
     *
     * Overridden to assign only relative rotation.
     *
     * @param transform - Global bone position and rotation
     * @param bone - Reference to bone instance
     * @override
     */
    protected alignBone(transform: BoneTransform, bone: babylon.TransformNode): void;
}

/**
 * Body patch plugin
 *
 * Plugin patches (inpaints/erases) foreground region of image defined by
 * body segmentation mask from {@link @geenee/bodyprocessors!PoseProcessor}.
 * It can be used in avatar virtual try to remove parts of a user's body
 * that stick out (not covered). Evaluation of body segmentation must be
 * enabled in {@link @geenee/bodyprocessors!PoseProcessor#init | init()}
 * method enabling {@link @geenee/bodyprocessors!PoseParams#mask} flag.
 */
declare class BodyPatchPlugin extends ShaderPlugin<PoseResult> {
    /** Segmentation mask texture */
    protected maskTexture?: ImageTexture;
    /** Image dilation shader */
    protected dilationShader?: DilationShader;
    /**
     * Constructor
     */
    constructor();
    /**
     * Initialize plugin
     *
     * Initializes resources required for shader effect.
     *
     * @param renderer - Renderer this plugin is attached to
     * @returns Promise resolving when initialization is finished
     * @override
     */
    load(renderer: Renderer<PoseResult>): Promise<void>;
    /**
     * Reset plugin
     *
     * Releases all resources and instances created in load().
     *
     * @override
     */
    unload(): void;
    /**
     * Process the image
     *
     * Patches (inpaints) foreground image pixels
     * according to provided segmentation mask.
     *
     * @param result - Results of video processing
     * @param input - Current image texture
     * @returns True on success, false otherwise
     * @override
     */
    process(result: PoseResult, input: WebGLTexture): boolean;
}

/**
 * Body part patch plugin
 *
 * Plugin conditionally patches (inpaints/erases) foreground
 * regions of image defined by body segmentation mask from
 * {@link @geenee/bodyprocessors!PoseProcessor}. There are
 * 2 types of regions: "patch" and "keep", both are defined
 * by corresponding sets of scene meshes. Plugin patches
 * foreground/masked pixels that belong to "patch" regions
 * but are not part of "keep" regions. This can be used in
 * apparel virtual try to remove parts of a body that stick
 * out of (not covered by) outfit. In this case, "patch"
 * region is defined by outfit meshes and "keep" region is
 * the reference body model that at the same time serves as
 * {@link OccluderMaterial | occluder}. BodypartPatchPlugin
 * is compatible with {@link BabylonUniRenderer} derivatives.
 * Evaluation of body segmentation mask must be enabled in
 * {@link @geenee/bodyprocessors!PoseProcessor#init} setting
 * {@link @geenee/bodyprocessors!PoseParams#mask} to true.
 */
declare class BodypartPatchPlugin extends ShaderPlugin<PoseResult> {
    protected patchParts: babylon.AbstractMesh[];
    protected keepParts: babylon.AbstractMesh[];
    /** Segmentation mask texture */
    protected maskTexture?: ImageTexture;
    /** Image dilation shader */
    protected dilationShader?: DilationShader;
    /** Render target for patch regions */
    protected partsTarget?: babylon.RenderTargetTexture;
    /** Skeletons of skinned meshes */
    protected partsSkeletons: babylon.Skeleton[];
    /** Material of "patch" parts */
    protected patchMaterial?: babylon.StandardMaterial;
    /** Material of "keep" parts */
    protected keepMaterial?: babylon.StandardMaterial;
    /**
     * Constructor
     *
     * @param patchParts - Meshes defining "patch" regions
     * @param keepParts - Meshes defining "keep" regions
     */
    constructor(patchParts?: babylon.AbstractMesh[], keepParts?: babylon.AbstractMesh[]);
    /**
     * Set meshes defining patch regions
     *
     * @param patchParts - Meshes defining "patch" regions
     * @param keepParts - Meshes defining "keep" regions
     */
    setParts(patchParts?: babylon.AbstractMesh[], keepParts?: babylon.AbstractMesh[]): void;
    /**
     * Initialize plugin
     *
     * Initializes resources required for shader effect.
     *
     * @param renderer - Renderer this plugin is attached to
     * @returns Promise resolving when initialization is finished
     * @override
     */
    load(renderer: Renderer<PoseResult>): Promise<void>;
    /**
     * Reset plugin
     *
     * Releases all resources and instances created in load().
     *
     * @override
     */
    unload(): void;
    /**
     * Process the image
     *
     * Patches (inpaints) foreground image pixels according to
     * the provided segmentation mask. Patched pixels must also
     * belong to "patch" region and not be a part of "keep" region.
     * Regions are defined by corresponding sets of scene meshes.
     *
     * @param result - Results of video processing
     * @param input - Current image texture
     * @returns True on success, false otherwise
     * @override
     */
    process(result: PoseResult, input: WebGLTexture): boolean;
    /**
     * Set video size
     *
     * Adjusts shader and texture to a new size.
     *
     * @override
     */
    setupVideo(size: Size): void;
}

/**
 * Occluder plugin
 *
 * Plugin making provided node an occluder. Usually
 * node is a base mesh (average approximation) of a
 * body representing its real counterpart in a scene.
 * Occluders are not rendered by themselves but still
 * participate in occlusion queries. This is achieved
 * by setting `disableColorWrite=true` to materials of
 * node's meshes. This flag tells rendering engine to
 * not write to color buffer but still write to depth
 * buffer. Then meshes are effectively not rendered
 * (fragment color write is skipped) and only occlude
 * all other meshes of the scene (during depth test).
 */
declare class OccluderPlugin extends BabylonPlugin<any> {
    protected node: babylon.TransformNode;
    protected renderOrder: number;
    /**
     * Constructor
     *
     * @param node - Scene node of an occluder
     * @param renderOrder - Render order (0,1,2,3)
     */
    constructor(node: babylon.TransformNode, renderOrder?: number);
    /**
     * Initialize plugin
     *
     * Sets `disableColorWrite=true` to node's materials.
     * This tells rendering engine to not write to color
     * buffer, but still write to depth buffer. This way
     * mesh is effectively not drawn (color buffer) but
     * occludes other meshes of the scene (depth test).
     *
     * @param renderer - Renderer this plugin is attached to
     * @returns Promise resolving when initialization is finished
     * @override
     */
    load(renderer: Renderer<any>): Promise<void>;
}

/**
 * Occluder material
 *
 * Occluders are elements of a scene that are not rendered
 * by themselves but still participate in occlusion queries.
 * Usually, occluder is a base mesh (average approximation)
 * of a body representing its real counterpart in a scene.
 * Occluders are used to mask visible virtual objects behind
 * them (like geometries of a 3D scene behind user's body).
 * Applying OccluderMaterial to a mesh makes it an occluder.
 */
declare class OccluderMaterial extends babylon.StandardMaterial {
    /**
     * Constructor
     *
     * @param name - Name of the material in the scene
     * @param scene - Scene the material belongs to
     */
    constructor(name: string, scene?: babylon.Scene);
}

export { BabylonPlugin, BabylonRenderer, BabylonUniRenderer, BodyPatchPlugin, BodypartPatchPlugin, BoneTransform, FaceMaskPlugin, FacePlugin, FaceRenderer, FaceTrackPlugin, HeadTrackPlugin, OccluderMaterial, OccluderPlugin, PoseAlignPlugin, PoseOutfitPlugin, PosePlugin, PoseRenderer, PoseTwinPlugin, SkeletonTransforms };
